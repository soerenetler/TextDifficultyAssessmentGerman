{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:56<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from math import log \n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "frequencyFileList = [\"5000frequency.txt\", \"10000frequency.txt\", \"15000frequency.txt\", \"20000frequency.txt\", \"25000frequency.txt\", \"30000frequency.txt\", \"35000frequency.txt\", \"40000frequency.txt\", \"45000frequency.txt\"]\n",
    "freqdict = defaultdict(int)\n",
    "possibleValues = []\n",
    "\n",
    "for fileName in tqdm(frequencyFileList):\n",
    "    file = open(\"frequencyLists/\" + fileName)\n",
    "    allString = file.read()\n",
    "    for index, word in enumerate(allString.split(\" \")[1::2]):\n",
    "        possibleValues.append(int(allString.split(\" \")[index*2]))\n",
    "        freqdict[word] = log(int(allString.split(\" \")[index*2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2563 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█▏        | 289/2563 [00:00<00:00, 2870.72it/s]\u001b[A\n",
      " 24%|██▍       | 609/2563 [00:00<00:00, 3031.98it/s]\u001b[A\n",
      " 35%|███▌      | 900/2563 [00:00<00:00, 2988.79it/s]\u001b[A\n",
      " 43%|████▎     | 1097/2563 [00:00<00:00, 2664.51it/s]\u001b[A\n",
      " 50%|█████     | 1289/2563 [00:00<00:00, 2378.87it/s]\u001b[A\n",
      " 57%|█████▋    | 1467/2563 [00:00<00:00, 2256.58it/s]\u001b[A\n",
      " 64%|██████▍   | 1641/2563 [00:00<00:00, 1950.32it/s]\u001b[A\n",
      " 70%|██████▉   | 1791/2563 [00:01<00:00, 1714.81it/s]\u001b[A\n",
      " 75%|███████▍  | 1918/2563 [00:01<00:00, 1655.15it/s]\u001b[A\n",
      " 80%|███████▉  | 2040/2563 [00:01<00:00, 1583.11it/s]\u001b[A\n",
      " 84%|████████▍ | 2154/2563 [00:01<00:00, 1521.43it/s]\u001b[A\n",
      " 88%|████████▊ | 2261/2563 [00:01<00:00, 1442.16it/s]\u001b[A\n",
      " 93%|█████████▎| 2377/2563 [00:01<00:00, 1425.02it/s]\u001b[A\n",
      " 98%|█████████▊| 2508/2563 [00:01<00:00, 1418.31it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.07s/it].14it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_files = os.listdir(\"/home/soeren/Documents/TextDifficultyAssessmentGerman/datasets/RandomText/FeatureSet1_BF\")\n",
    "input_files = [\"01_Preprocessing_df.csv\"]\n",
    "\n",
    "def save_df(path,df):\n",
    "    df.to_csv(path,sep=\"|\",index=False)\n",
    "\n",
    "for input_file in tqdm(input_files):\n",
    "    df = pd.read_csv(\"datasets/RandomText/FeatureSet3_LV/\" + input_file, sep=\"|\", lineterminator = '\\n')\n",
    "    df[\"preprocessedText\"]  = [ast.literal_eval(text) for text in df[\"RFTagger\"]]\n",
    "    meanFreq = []\n",
    "    medianFreq = []\n",
    "    stdFreq = []\n",
    "    bin0=[]\n",
    "    bin1=[]\n",
    "    bin2=[]\n",
    "    bin3=[]\n",
    "    bin4=[]\n",
    "    bin5=[]\n",
    "    bin6=[]\n",
    "    bin7=[]\n",
    "    bin8=[]\n",
    "    bin9=[]\n",
    "    bin10=[]\n",
    "    bin11=[]\n",
    "    bin12=[]\n",
    "    bin13=[]\n",
    "    bin14=[]\n",
    "\n",
    "    for text in tqdm(df[\"preprocessedText\"]):\n",
    "        freqvalues=[]\n",
    "\n",
    "        for sentence in text:\n",
    "            for word in sentence:\n",
    "                if word[1]!= \"SYM\":\n",
    "                    freqvalues.append(freqdict[word[0]])\n",
    "\n",
    "        meanFreq.append(np.mean(freqvalues))\n",
    "        medianFreq.append(np.median(freqvalues))\n",
    "        stdFreq.append(np.std(freqvalues))\n",
    "        bin0.append(sum([1 for freqvalue in freqvalues if freqvalue == 0 ])/len(freqvalues))\n",
    "        bin1.append(sum([1 for freqvalue in freqvalues if freqvalue > 0 and freqvalue < 1 ])/len(freqvalues))\n",
    "        bin2.append(sum([1 for freqvalue in freqvalues if freqvalue > 1 and freqvalue < 2 ])/len(freqvalues))\n",
    "        bin3.append(sum([1 for freqvalue in freqvalues if freqvalue > 2 and freqvalue < 3 ])/len(freqvalues))\n",
    "        bin4.append(sum([1 for freqvalue in freqvalues if freqvalue > 3 and freqvalue < 4 ])/len(freqvalues))\n",
    "        bin5.append(sum([1 for freqvalue in freqvalues if freqvalue > 4 and freqvalue < 5 ])/len(freqvalues))\n",
    "        bin6.append(sum([1 for freqvalue in freqvalues if freqvalue > 5 and freqvalue < 6 ])/len(freqvalues))\n",
    "        bin7.append(sum([1 for freqvalue in freqvalues if freqvalue > 6 and freqvalue < 7 ])/len(freqvalues))\n",
    "        bin8.append(sum([1 for freqvalue in freqvalues if freqvalue > 7 and freqvalue < 8 ])/len(freqvalues))\n",
    "        bin9.append(sum([1 for freqvalue in freqvalues if freqvalue > 8 and freqvalue < 9 ])/len(freqvalues))\n",
    "        bin10.append(sum([1 for freqvalue in freqvalues if freqvalue > 9 and freqvalue < 10 ])/len(freqvalues))\n",
    "        bin11.append(sum([1 for freqvalue in freqvalues if freqvalue > 10 and freqvalue < 11 ])/len(freqvalues))\n",
    "        bin12.append(sum([1 for freqvalue in freqvalues if freqvalue > 11 and freqvalue < 12 ])/len(freqvalues))\n",
    "        bin13.append(sum([1 for freqvalue in freqvalues if freqvalue > 12 and freqvalue < 13 ])/len(freqvalues))\n",
    "        bin14.append(sum([1 for freqvalue in freqvalues if freqvalue > 13 and freqvalue < 14 ])/len(freqvalues))\n",
    "\n",
    "\n",
    "    df[\"FF-meanFreq\"] = meanFreq\n",
    "    df[\"FF-medianFreq\"] = medianFreq\n",
    "    df[\"FF-bin0\"] = bin0\n",
    "    df[\"FF-bin1\"] = bin1\n",
    "    df[\"FF-bin2\"] = bin2\n",
    "    df[\"FF-bin3\"] = bin3\n",
    "    df[\"FF-bin4\"] = bin4\n",
    "    df[\"FF-bin5\"] = bin5\n",
    "    df[\"FF-bin6\"] = bin6\n",
    "    df[\"FF-bin7\"] = bin7\n",
    "    df[\"FF-bin8\"] = bin8\n",
    "    df[\"FF-bin9\"] = bin9\n",
    "    df[\"FF-bin10\"] = bin10\n",
    "    df[\"FF-bin11\"] = bin11\n",
    "    df[\"FF-bin12\"] = bin12\n",
    "    df[\"FF-bin13\"] = bin13\n",
    "    df[\"FF-bin14\"] = bin14\n",
    "    \n",
    "    filename = \"datasets/RandomText/FeatureSet4_FF/\" + input_file\n",
    "    save_df(filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
