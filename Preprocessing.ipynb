{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>Meine Familie</td>\n",
       "      <td>Zu meiner Familie gehören vier Personen. Die M...</td>\n",
       "      <td>https://german.net/reading/familie/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>Maria und ihre Familie</td>\n",
       "      <td>Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...</td>\n",
       "      <td>https://german.net/reading/marias-familie/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>Ich bin Tom</td>\n",
       "      <td>Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...</td>\n",
       "      <td>https://german.net/reading/tom/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1</td>\n",
       "      <td>Freundinnen</td>\n",
       "      <td>Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...</td>\n",
       "      <td>https://german.net/reading/freundinnen/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1</td>\n",
       "      <td>Einkaufen im Supermarkt</td>\n",
       "      <td>Frau Meier geht heute in den Supermarkt. Ihr M...</td>\n",
       "      <td>https://german.net/reading/einkaufen/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level                    Title  \\\n",
       "0    A1            Meine Familie   \n",
       "1    A1   Maria und ihre Familie   \n",
       "2    A1              Ich bin Tom   \n",
       "3    A1              Freundinnen   \n",
       "4    A1  Einkaufen im Supermarkt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Zu meiner Familie gehören vier Personen. Die M...   \n",
       "1  Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...   \n",
       "2  Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...   \n",
       "3  Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...   \n",
       "4  Frau Meier geht heute in den Supermarkt. Ihr M...   \n",
       "\n",
       "                                       Source     Type  \n",
       "0         https://german.net/reading/familie/  Reading  \n",
       "1  https://german.net/reading/marias-familie/  Reading  \n",
       "2             https://german.net/reading/tom/  Reading  \n",
       "3     https://german.net/reading/freundinnen/  Reading  \n",
       "4       https://german.net/reading/einkaufen/  Reading  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTSLyp3Ev2bxe8pnHStFtbdwg-EhvbMEhEUzRsaFjC0sKVQ-OzyD8LbAjM9iYoG2LSmSTAGGFfed4I9/pub?gid=0&single=true&output=csv\"\n",
    "\n",
    "s=requests.get(url).content\n",
    "df=pd.read_csv(StringIO(s.decode('utf-8')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "import re\n",
    "def clean(text):\n",
    "    text = re.sub(\"Stadt X\\,?\\.?\\s?(den )?\\d+((\\,)|(\\.)|(\\-))\\d+((\\,)|(\\.)|(\\. )|(\\-))\\d+ \", \"\", text)\n",
    "    text = re.sub(\"^.{10,250}Sehr gee?h?e?e?rte?( Damen )?((und)|(oder))? He?er?ren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,100}Sehr Geherte mein Damen und Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,100}Liebe Dana\", \"Liebe Dana\", text)\n",
    "    text = re.sub(\"^.{10,100}Lieber? Silke\", \"Liebe Silke\", text)\n",
    "    text = re.sub(\"^.{10,100}Liebe Maria\", \"Liebe Maria\", text)\n",
    "    text = re.sub(\"^.{10,100}Liebe Katharina\", \"Liebe Katharina\", text)\n",
    "    text = re.sub(\"(\\S+)\\.(\\S+)\", r\"\\1. \\2\", text)\n",
    "    text = re.sub(\"www. \", r\"www.\", text)\n",
    "    text = re.sub(\"^.{10,100}Lieber Michael\", \"Lieber Michael\", text)\n",
    "    text = re.sub(\"^.{10,100}Lieber Ingo\", \"Lieber Ingo\", text)\n",
    "    text = re.sub(\"^.{10,100}Lieber Julia\", \"Lieber Julia\", text)\n",
    "    text = re.sub(\"^.{10,100}Lieber Eva\", \"Lieber Eva\", text)\n",
    "    text = re.sub(\"^.{10,100}Hallo Eva\", \"Hallo Eva\", text)\n",
    "    text = re.sub(\"^.{10,100}Liebe Julia\", \"Liebe Julia\", text)\n",
    "    text = re.sub(\"^.{10,100}Hallo Julia\", \"Hallo Julia\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geerhte Damen und Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr Geehrte Damen und Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehrte Damen und Herrn\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}See?hr gerrhte Herren und Damen\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehte Damen und Herr\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Seehr geehrte Damen und Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Seher geherte Damen und Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geherte Herrn\", \"Sehr geehrte Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehrte Fir\", \"Sehr geehrte Fir\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehrte Damen u. Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehrte Damen u Herren\", \"Sehr geehrte Damen und Herren\", text)\n",
    "    text = re.sub(\"^.{10,200}Seehr Geehrte Damen und He\", \"Sehr geehrte Damen und He\", text)\n",
    "    text = re.sub(\"^.{10,200}Sehr geehrte Au-\", \"Sehr geehrte Au-\", text)\n",
    "    return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>Meine Familie</td>\n",
       "      <td>Zu meiner Familie gehören vier Personen. Die M...</td>\n",
       "      <td>https://german.net/reading/familie/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>Maria und ihre Familie</td>\n",
       "      <td>Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...</td>\n",
       "      <td>https://german.net/reading/marias-familie/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>Ich bin Tom</td>\n",
       "      <td>Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...</td>\n",
       "      <td>https://german.net/reading/tom/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1</td>\n",
       "      <td>Freundinnen</td>\n",
       "      <td>Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...</td>\n",
       "      <td>https://german.net/reading/freundinnen/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1</td>\n",
       "      <td>Einkaufen im Supermarkt</td>\n",
       "      <td>Frau Meier geht heute in den Supermarkt. Ihr M...</td>\n",
       "      <td>https://german.net/reading/einkaufen/</td>\n",
       "      <td>Reading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level                    Title  \\\n",
       "0    A1            Meine Familie   \n",
       "1    A1   Maria und ihre Familie   \n",
       "2    A1              Ich bin Tom   \n",
       "3    A1              Freundinnen   \n",
       "4    A1  Einkaufen im Supermarkt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Zu meiner Familie gehören vier Personen. Die M...   \n",
       "1  Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...   \n",
       "2  Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...   \n",
       "3  Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...   \n",
       "4  Frau Meier geht heute in den Supermarkt. Ihr M...   \n",
       "\n",
       "                                       Source     Type  \n",
       "0         https://german.net/reading/familie/  Reading  \n",
       "1  https://german.net/reading/marias-familie/  Reading  \n",
       "2             https://german.net/reading/tom/  Reading  \n",
       "3     https://german.net/reading/freundinnen/  Reading  \n",
       "4       https://german.net/reading/einkaufen/  Reading  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['make'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "url = \"http://www.cis.uni-muenchen.de/~schmid/tools/RFTagger/data/RFTagger.tar.gz\"\n",
    "filename = \"RFTagger.tar.gz\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "import tarfile\n",
    "tar = tarfile.open(filename)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "from subprocess import run\n",
    "run([\"make\"], cwd=\"RFTagger/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def preprocessing(text):\n",
    "    file = open(\"RFTagger/temp.txt\", \"w\")\n",
    "    file.write(\"\\n\\n\".join(\"\\n\".join(word_tokenize(sentence, language='german')) for sentence in sent_tokenize(text, language='german')))\n",
    "    file.close()\n",
    "    test_tagged = check_output([\"src/rft-annotate\", \"lib/german.par\", \"temp.txt\"], cwd=\"RFTagger\").decode(\"utf-8\").split(\"\\n\")\n",
    "    \n",
    "    sent_indecies = [index for index in range(len(test_tagged)) if test_tagged[index] == '']\n",
    "    sent_indecies = [-1] + sent_indecies\n",
    "\n",
    "    test_tagged_saparated= []\n",
    "    for entry in test_tagged:\n",
    "        temp = entry.split(\"\\t\")\n",
    "        if len(temp) == 2:\n",
    "            test_tagged_saparated.append([temp[0]] + temp[1].split(\".\"))# + [temp[2]])\n",
    "        else:\n",
    "            test_tagged_saparated.append([])\n",
    "\n",
    "    output = []\n",
    "    for start, end in zip(sent_indecies, sent_indecies[1:]):\n",
    "        output.append(test_tagged_saparated[start+1: end])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./stanford-corenlp-full-2018-02-27/stanford-german-corenlp-2018-02-27-models.jar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install standordcorenlp\n",
    "#!apt install openjdk-11-jre\n",
    "\n",
    "#download Stanford Parser\n",
    "import urllib\n",
    "url = \"http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip\"\n",
    "filename = \"stanford-corenlp-full-2018-02-27.zip\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "import zipfile\n",
    "zip_obj = zipfile.ZipFile(filename)\n",
    "zip_obj.extractall()\n",
    "zip_obj.close()\n",
    "\n",
    "url = \"http://nlp.stanford.edu/software/stanford-german-corenlp-2018-02-27-models.jar\"\n",
    "filename = \"stanford-german-corenlp-2018-02-27-models.jar\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "import shutil\n",
    "shutil.move(\"./stanford-german-corenlp-2018-02-27-models.jar\", \"./stanford-corenlp-full-2018-02-27/stanford-german-corenlp-2018-02-27-models.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanford parser\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import sys\n",
    "\n",
    "    \n",
    "def parsing(text):\n",
    "    output=[]\n",
    "    text = sent_tokenize(text)\n",
    "    trees=[]\n",
    "    \n",
    "    for sentence in text:\n",
    "        try:\n",
    "            tree = re.sub(\" +\", \" \", nlp.parse(sentence).replace(\"\\n\", \"\"))\n",
    "            output.append(tree)\n",
    "        except ValueError:\n",
    "            output.append(\"\")\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def executer(df, function, part_of_df, new_column):\n",
    "    result = []\n",
    "    for entry in tqdm(df[part_of_df]):\n",
    "        result.append(function(entry))\n",
    "    df[new_column]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1431/1431 [00:00<00:00, 2583.18it/s]\n",
      "100%|██████████| 1431/1431 [18:21<00:00,  1.30it/s]\n",
      "  1%|          | 11/1431 [03:43<7:59:58, 20.28s/it]"
     ]
    }
   ],
   "source": [
    "executer(df, clean, \"Text\", \"cleanedText\")\n",
    "executer(df, preprocessing, \"cleanedText\", \"RFTagger\")\n",
    "nlp = StanfordCoreNLP(r'./stanford-corenlp-full-2018-02-27', lang='de', memory='4g')\n",
    "executer(df, parsing, \"cleanedText\", \"parsedText\")\n",
    "nlp.close()  # Do not forget to close! The backend server will consume a lot memory.\n",
    "df[\"newLevel\"] = [element[0] for element in df[Level]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(path,df):\n",
    "    df.to_csv(path,sep=\"|\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(n=100))\n",
    "filename = \"preprocessed_text_df.csv\"\n",
    "save_df(filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1138it [00:00, 2802.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>levelsText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zu meiner Familie gehören vier Personen.</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Mutter bin ich und dann gehört natürlich m...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wir haben zwei Kinder, einen Sohn, der sechs J...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wir wohnen in einem kleinen Haus mit einem Gar...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dort können die Kinder ein bisschen spielen.</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences levelsText\n",
       "0           Zu meiner Familie gehören vier Personen.         A1\n",
       "1  Die Mutter bin ich und dann gehört natürlich m...         A1\n",
       "2  Wir haben zwei Kinder, einen Sohn, der sechs J...         A1\n",
       "3  Wir wohnen in einem kleinen Haus mit einem Gar...         A1\n",
       "4       Dort können die Kinder ein bisschen spielen.         A1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Create Sentence Dataset###\n",
    "levelsText = []\n",
    "sentences = []\n",
    "for text, level in tqdm(zip(df[\"cleanedText\"], df[\"Level\"])):\n",
    "    for sentence in sent_tokenize(text):\n",
    "        levelsText.append(level)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "sentence_df= pd.DataFrame()\n",
    "sentence_df[\"sentences\"] = sentences\n",
    "sentence_df[\"levelsText\"] = levelsText\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8605/12846 [64:31:10<31:47:55, 26.99s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9a7d83256b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecuter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RFTagger\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'./stanford-corenlp-full-2018-02-27'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'4g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexecuter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parsedText\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Do not forget to close! The backend server will consume a lot memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5d5279d03f3>\u001b[0m in \u001b[0;36mexecuter\u001b[0;34m(df, function, part_of_df, new_column)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_of_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-975c8d820ad4>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'german'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'german'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src/rft-annotate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib/german.par\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"temp.txt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RFTagger\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msent_indecies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtest_tagged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 336\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "executer(sentence_df, preprocessing, \"sentences\", \"RFTagger\")\n",
    "nlp = StanfordCoreNLP(r'./stanford-corenlp-full-2018-02-27', lang='de', memory='4g')\n",
    "executer(sentence_df, parsing, \"sentences\", \"parsedText\")\n",
    "nlp.close()  # Do not forget to close! The backend server will consume a lot memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sentence_df.head(n=100))\n",
    "filename = \"preprocessed_sentence_df.csv\"\n",
    "save_df(filename, sentence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
