{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compound splitter\n",
    "'''\n",
    "\n",
    "# https://github.com/dtuggener/CharSplit\n",
    "import urllib\n",
    "url = \"https://github.com/dtuggener/CharSplit/archive/master.zip\"\n",
    "filename = \"CharSplit.zip\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "import os, sys\n",
    "#os.rename(\"CharSplit-master\", \"CharSplit\")\n",
    "from shutil import copyfile\n",
    "for filename in os.listdir(\"CharSplit-master\"):\n",
    "    if filename != \"README.md\": \n",
    "        copyfile(\"CharSplit-master/\" + filename, filename)\n",
    "    \n",
    "import char_split, ngram_probs\n",
    "def compoundSplit(string):\n",
    "    request = char_split.split_compound(string)[0]\n",
    "    if request[0] <= 0:\n",
    "        return [string]\n",
    "    else:\n",
    "        return compoundSplit(request[1]) + compoundSplit(request[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MO-*</th>\n",
       "      <th>MO--</th>\n",
       "      <th>MO-1</th>\n",
       "      <th>MO-2</th>\n",
       "      <th>MO-3</th>\n",
       "      <th>MO-ADJA</th>\n",
       "      <th>MO-ADJD</th>\n",
       "      <th>MO-ADV</th>\n",
       "      <th>MO-APPO</th>\n",
       "      <th>MO-APPR</th>\n",
       "      <th>...</th>\n",
       "      <th>MO-auxverbs2verbs</th>\n",
       "      <th>MO-verbspersent</th>\n",
       "      <th>MO-nom2nouns</th>\n",
       "      <th>MO-gen2nouns</th>\n",
       "      <th>MO-dat2nouns</th>\n",
       "      <th>MO-acc2nouns</th>\n",
       "      <th>MO-keit2nouns</th>\n",
       "      <th>MO-ung2nouns</th>\n",
       "      <th>MO-werk2nouns</th>\n",
       "      <th>MO-compounds2nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110465</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121528</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205882</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MO-*      MO--      MO-1  MO-2      MO-3   MO-ADJA   MO-ADJD    MO-ADV  \\\n",
       "0  0.142857  0.092437  0.075630   0.0  0.117647  0.016807  0.025210  0.100840   \n",
       "1  0.081395  0.104651  0.093023   0.0  0.110465  0.005814  0.034884  0.058140   \n",
       "2  0.046512  0.108527  0.093023   0.0  0.116279  0.000000  0.031008  0.038760   \n",
       "3  0.052174  0.052174  0.000000   0.0  0.217391  0.034783  0.017391  0.113043   \n",
       "4  0.097222  0.045139  0.072917   0.0  0.121528  0.013889  0.017361  0.052083   \n",
       "\n",
       "   MO-APPO   MO-APPR         ...          MO-auxverbs2verbs  MO-verbspersent  \\\n",
       "0      0.0  0.075630         ...                        0.0         1.230769   \n",
       "1      0.0  0.069767         ...                        0.0         1.300000   \n",
       "2      0.0  0.038760         ...                        0.0         1.333333   \n",
       "3      0.0  0.069565         ...                        0.0         1.266667   \n",
       "4      0.0  0.038194         ...                        0.0         1.205882   \n",
       "\n",
       "   MO-nom2nouns  MO-gen2nouns  MO-dat2nouns  MO-acc2nouns  MO-keit2nouns  \\\n",
       "0      0.375000      0.000000      0.291667      0.333333            0.0   \n",
       "1      0.534884      0.023256      0.186047      0.255814            0.0   \n",
       "2      0.583333      0.000000      0.138889      0.277778            0.0   \n",
       "3      0.300000      0.033333      0.366667      0.300000            0.0   \n",
       "4      0.615385      0.000000      0.087912      0.296703            0.0   \n",
       "\n",
       "   MO-ung2nouns  MO-werk2nouns  MO-compounds2nouns  \n",
       "0           0.0            0.0            0.500000  \n",
       "1           0.0            0.0            0.232558  \n",
       "2           0.0            0.0            0.500000  \n",
       "3           0.0            0.0            0.166667  \n",
       "4           0.0            0.0            0.241758  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MO-*', 'MO--', 'MO-1', 'MO-2', 'MO-3', 'MO-ADJA', 'MO-ADJD', 'MO-ADV', 'MO-APPO', 'MO-APPR', 'MO-APPRART', 'MO-APZR', 'MO-ART', 'MO-Aber', 'MO-Acc', 'MO-Adj', 'MO-Als', 'MO-An', 'MO-Ans', 'MO-Attr', 'MO-Auf', 'MO-Aux', 'MO-Außer', 'MO-Bis', 'MO-CARD', 'MO-CONJ', 'MO-Colon', 'MO-Comma', 'MO-Comp', 'MO-Cont', 'MO-Coord', 'MO-Dat', 'MO-Def', 'MO-Deg', 'MO-Dem', 'MO-Denn', 'MO-Doch', 'MO-FM', 'MO-Fem', 'MO-Full', 'MO-Gen', 'MO-Haben', 'MO-Hinter', 'MO-Hyph', 'MO-ITJ', 'MO-In', 'MO-Ind', 'MO-Indef', 'MO-Inter', 'MO-Left', 'MO-Masc', 'MO-Mod', 'MO-N', 'MO-Name', 'MO-Neg', 'MO-Neut', 'MO-Noch', 'MO-Nom', 'MO-Noun', 'MO-Other', 'MO-PART', 'MO-PRO', 'MO-PROADV', 'MO-Paren', 'MO-Past', 'MO-Per', 'MO-Pers', 'MO-Pl', 'MO-Pos', 'MO-Poss', 'MO-Pres', 'MO-Pro', 'MO-Psp', 'MO-Pun', 'MO-Quot', 'MO-Refl', 'MO-Reg', 'MO-Rel', 'MO-Right', 'MO-SYM', 'MO-Sein', 'MO-Sent', 'MO-Sg', 'MO-Slash', 'MO-SubFin', 'MO-SubInf', 'MO-Subj', 'MO-Subst', 'MO-Sup', 'MO-TRUNC', 'MO-Unter', 'MO-VFIN', 'MO-VIMP', 'MO-VINF', 'MO-VPP', 'MO-Verb', 'MO-Vor', 'MO-Wie', 'MO-XY', 'MO-Zu', 'MO-Zwischen', 'MO-zu', 'MO-Über', 'MO-inf2verbs', 'MO-part2verbs', 'MO-imp2verbs', 'MO-1st2finverbs', 'MO-2nd2finverbs', 'MO-3rd2finverbs', 'MO-subj2finverbs', 'MO-finverbs2verbs', 'MO-modverbs2verbs', 'MO-auxverbs2verbs', 'MO-verbspersent', 'MO-nom2nouns', 'MO-gen2nouns', 'MO-dat2nouns', 'MO-acc2nouns', 'MO-keit2nouns', 'MO-ung2nouns', 'MO-werk2nouns', 'MO-compounds2nouns']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Type</th>\n",
       "      <th>cleanedText</th>\n",
       "      <th>RFTagger</th>\n",
       "      <th>parsedText</th>\n",
       "      <th>newLevel</th>\n",
       "      <th>MO-*</th>\n",
       "      <th>...</th>\n",
       "      <th>MO-auxverbs2verbs</th>\n",
       "      <th>MO-verbspersent</th>\n",
       "      <th>MO-nom2nouns</th>\n",
       "      <th>MO-gen2nouns</th>\n",
       "      <th>MO-dat2nouns</th>\n",
       "      <th>MO-acc2nouns</th>\n",
       "      <th>MO-keit2nouns</th>\n",
       "      <th>MO-ung2nouns</th>\n",
       "      <th>MO-werk2nouns</th>\n",
       "      <th>MO-compounds2nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>Meine Familie</td>\n",
       "      <td>Zu meiner Familie gehören vier Personen. Die M...</td>\n",
       "      <td>https://german.net/reading/familie/</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Zu meiner Familie gehören vier Personen. Die M...</td>\n",
       "      <td>[[['Zu', 'APPR', 'Dat'], ['meiner', 'PRO', 'Po...</td>\n",
       "      <td>['(ROOT (S (PP (APPR Zu) (PPOSAT meiner) (NN F...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>Maria und ihre Familie</td>\n",
       "      <td>Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...</td>\n",
       "      <td>https://german.net/reading/marias-familie/</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...</td>\n",
       "      <td>[[['Mein', 'PRO', 'Poss', 'Attr', '-', 'Nom', ...</td>\n",
       "      <td>['(ROOT (S (NP (PPOSAT Mein) (NN Name)) (VAFIN...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>Ich bin Tom</td>\n",
       "      <td>Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...</td>\n",
       "      <td>https://german.net/reading/tom/</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...</td>\n",
       "      <td>[[['Hallo', 'ITJ'], ['!', 'SYM', 'Pun', 'Sent'...</td>\n",
       "      <td>['(ROOT (NUR (ITJ Hallo) ($. !)))', '(ROOT (S ...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1</td>\n",
       "      <td>Freundinnen</td>\n",
       "      <td>Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...</td>\n",
       "      <td>https://german.net/reading/freundinnen/</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...</td>\n",
       "      <td>[[['Ricarda', 'N', 'Name', 'Nom', 'Sg', 'Fem']...</td>\n",
       "      <td>['(ROOT (CS (S (NE Ricarda) (VAFIN ist) (AP (N...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1</td>\n",
       "      <td>Einkaufen im Supermarkt</td>\n",
       "      <td>Frau Meier geht heute in den Supermarkt. Ihr M...</td>\n",
       "      <td>https://german.net/reading/einkaufen/</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Frau Meier geht heute in den Supermarkt. Ihr M...</td>\n",
       "      <td>[[['Frau', 'N', 'Reg', 'Nom', 'Sg', 'Fem'], ['...</td>\n",
       "      <td>['(ROOT (S (NP (NN Frau) (NE Meier)) (VVFIN ge...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.205882</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level                    Title  \\\n",
       "0    A1            Meine Familie   \n",
       "1    A1   Maria und ihre Familie   \n",
       "2    A1              Ich bin Tom   \n",
       "3    A1              Freundinnen   \n",
       "4    A1  Einkaufen im Supermarkt   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Zu meiner Familie gehören vier Personen. Die M...   \n",
       "1  Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...   \n",
       "2  Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...   \n",
       "3  Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...   \n",
       "4  Frau Meier geht heute in den Supermarkt. Ihr M...   \n",
       "\n",
       "                                       Source     Type  \\\n",
       "0         https://german.net/reading/familie/  Reading   \n",
       "1  https://german.net/reading/marias-familie/  Reading   \n",
       "2             https://german.net/reading/tom/  Reading   \n",
       "3     https://german.net/reading/freundinnen/  Reading   \n",
       "4       https://german.net/reading/einkaufen/  Reading   \n",
       "\n",
       "                                         cleanedText  \\\n",
       "0  Zu meiner Familie gehören vier Personen. Die M...   \n",
       "1  Mein Name ist Maria. Ich bin 30 Jahre alt. Zu ...   \n",
       "2  Hallo! Ich bin Tom Maier. Ich bin 13 Jahre alt...   \n",
       "3  Ricarda ist 21 Jahre alt und wohnt in Lübeck. ...   \n",
       "4  Frau Meier geht heute in den Supermarkt. Ihr M...   \n",
       "\n",
       "                                            RFTagger  \\\n",
       "0  [[['Zu', 'APPR', 'Dat'], ['meiner', 'PRO', 'Po...   \n",
       "1  [[['Mein', 'PRO', 'Poss', 'Attr', '-', 'Nom', ...   \n",
       "2  [[['Hallo', 'ITJ'], ['!', 'SYM', 'Pun', 'Sent'...   \n",
       "3  [[['Ricarda', 'N', 'Name', 'Nom', 'Sg', 'Fem']...   \n",
       "4  [[['Frau', 'N', 'Reg', 'Nom', 'Sg', 'Fem'], ['...   \n",
       "\n",
       "                                          parsedText newLevel      MO-*  \\\n",
       "0  ['(ROOT (S (PP (APPR Zu) (PPOSAT meiner) (NN F...        A  0.142857   \n",
       "1  ['(ROOT (S (NP (PPOSAT Mein) (NN Name)) (VAFIN...        A  0.081395   \n",
       "2  ['(ROOT (NUR (ITJ Hallo) ($. !)))', '(ROOT (S ...        A  0.046512   \n",
       "3  ['(ROOT (CS (S (NE Ricarda) (VAFIN ist) (AP (N...        A  0.052174   \n",
       "4  ['(ROOT (S (NP (NN Frau) (NE Meier)) (VVFIN ge...        A  0.097222   \n",
       "\n",
       "          ...          MO-auxverbs2verbs  MO-verbspersent  MO-nom2nouns  \\\n",
       "0         ...                        0.0         1.230769      0.375000   \n",
       "1         ...                        0.0         1.300000      0.534884   \n",
       "2         ...                        0.0         1.333333      0.583333   \n",
       "3         ...                        0.0         1.266667      0.300000   \n",
       "4         ...                        0.0         1.205882      0.615385   \n",
       "\n",
       "   MO-gen2nouns  MO-dat2nouns  MO-acc2nouns  MO-keit2nouns  MO-ung2nouns  \\\n",
       "0      0.000000      0.291667      0.333333            0.0           0.0   \n",
       "1      0.023256      0.186047      0.255814            0.0           0.0   \n",
       "2      0.000000      0.138889      0.277778            0.0           0.0   \n",
       "3      0.033333      0.366667      0.300000            0.0           0.0   \n",
       "4      0.000000      0.087912      0.296703            0.0           0.0   \n",
       "\n",
       "   MO-werk2nouns  MO-compounds2nouns  \n",
       "0            0.0            0.500000  \n",
       "1            0.0            0.232558  \n",
       "2            0.0            0.500000  \n",
       "3            0.0            0.166667  \n",
       "4            0.0            0.241758  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Functions for obtaining the morphological features.  Goals:\n",
    "\n",
    "• Derivational\n",
    "- hand-compiled list by Hancke et al (2012) \n",
    "\n",
    "• Inflectional (RFTagger)\n",
    "- mood, person, tense, type of verbs\n",
    "- case of nouns\n",
    "\n",
    "• Compound words\n",
    "\n",
    "'''\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict, Counter, deque\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import io\n",
    "import ast\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/soerenetler/TextDifficultyAssessmentGerman/master/preprocessed_text_df.csv\"\n",
    "df= pd.read_csv(url, sep=\"|\", lineterminator='\\n')\n",
    "\n",
    "# preprocessing Level classifications to get rid of unwanted data and \"B1 \" vs. \"B1\"\n",
    "df = df[(df[\"Level\"] == \"A1\")|(df[\"Level\"] == \"A2\")|(df[\"Level\"] == \"B1\")|(df[\"Level\"] == \"B1 \")|(df[\"Level\"] == \"B2\")|(df[\"Level\"] == \"C1\")|(df[\"Level\"] == \"C2\")]\n",
    "df = df.replace(\"B1 \",\"B1\")\n",
    "\n",
    "# returns a list of all the features included in the dataset, to be used as attributes in feature vector\n",
    "def get_all_features(df):\n",
    "    all_features = [] \n",
    "    index = 0\n",
    "    for all_sentences in df.loc[:,'RFTagger']:\n",
    "        if all_sentences is not None:\n",
    "            all_sentences = all_sentences[:-5] # remove the empty last sentence [] as following line won't work\n",
    "            all_sentences += \"]\" # nasty preprocessing necessary to keep list structure for literal_eval\n",
    "            all_sentences = ast.literal_eval(all_sentences)\n",
    "            for sentence in all_sentences:\n",
    "                for word_features in sentence:\n",
    "                    word_features = word_features[1:] #exclude the word itself and lemma at end (leads to too many features)                    \n",
    "                    for token in word_features:\n",
    "                        token = \"MO-\"+token\n",
    "                        if token not in all_features:\n",
    "                            all_features.append(token)\n",
    "            index += 1\n",
    "                    \n",
    "    return all_features\n",
    "\n",
    "def get_classifications(df):\n",
    "    y = []\n",
    "    \n",
    "    for classification in df.loc[:,'Level']:\n",
    "        y.append(classification)\n",
    "        \n",
    "    return y\n",
    "\n",
    "def add_morph_columns(df_document):\n",
    "    df_document[\"MO-inf2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-part2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-imp2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-1st2finverbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-2nd2finverbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-3rd2finverbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-subj2finverbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-finverbs2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-modverbs2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-auxverbs2verbs\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-verbspersent\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-nom2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-gen2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-dat2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-acc2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-keit2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-ung2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-werk2nouns\"] = np.zeros(len(df_document))\n",
    "    #df_document[\"MO-derived2nouns\"] = np.zeros(len(df_document))\n",
    "    df_document[\"MO-compounds2nouns\"] = np.zeros(len(df_document))\n",
    "    \n",
    "def fill_morph_features(df_document, word_list, morph_dict, index):\n",
    "    derived_list = [\"ant\", \"anten\", \"antin\", \"antinnen\", \"arium\", \"arien\", \"ast\", \"asten\", \"astin\", \"astinnen\", \n",
    "                    \"at\", \"ate\", \"ator\", \"atoren\", \"atorin\", \"atorinnen\", \"atur\", \"aturen\", \"ei\", \"eien\", \"er\", \n",
    "                    \"erin\", \"erinnen\", \"ent\", \"ents\", \"enz\", \"enzen\", 'eur', 'eure', 'eurin', 'eurinnen', 'heit', \n",
    "                    'heiten', 'ist', 'isten', 'istin', 'istinnen', 'ion', 'ionen', 'ismus', 'ismen', 'ität', \n",
    "                    'itäten', 'keit', 'keiten', 'ling', 'lingen', 'nis', 'nisse', 'schaft', 'schaften', 'tum', \n",
    "                    'tümer', 'ung', 'ungen', 'ur', 'werk', 'werke', 'wesen']\n",
    "    \n",
    "    total_derived = 0\n",
    "    total_nouns = morph_dict[\"N\"]\n",
    "    total_verbs = morph_dict[\"VFIN\"] + morph_dict[\"VINF\"] + morph_dict[\"VIMP\"] + morph_dict[\"VPP\"]\n",
    "    total_keit = 0\n",
    "    total_ung = 0\n",
    "    total_werk = 0\n",
    "    total_nom = morph_dict[\"Nom\"]\n",
    "    total_gen = morph_dict[\"Gen\"]\n",
    "    total_dat = morph_dict[\"Dat\"]\n",
    "    total_acc = morph_dict[\"Acc\"]\n",
    "    total_subj = morph_dict[\"Subj\"]\n",
    "    total_first = morph_dict[\"1\"]\n",
    "    total_second = morph_dict[\"2\"]\n",
    "    total_third = morph_dict[\"3\"]\n",
    "    total_compounds = 0\n",
    "    total_infinitives = morph_dict[\"VINF\"]\n",
    "    total_participles = morph_dict[\"PART\"]\n",
    "    total_imperatives = morph_dict[\"VIMP\"]\n",
    "    total_finite = morph_dict[\"VFIN\"]\n",
    "    total_modal = morph_dict[\"MOD\"]\n",
    "    total_auxiliary = morph_dict[\"AUX\"]\n",
    "    num_sentences = 1 + word_list.count(\".\")\n",
    "    \n",
    "    for word in word_list:          \n",
    "        for derivation in derived_list:\n",
    "            if word[(len(word)-len(derivation)):len(word)] == derivation:\n",
    "                #total_derived += 1\n",
    "                    \n",
    "                if derivation == \"keit\":\n",
    "                    total_keit += 1\n",
    "                elif derivation == \"ung\":\n",
    "                    total_ung += 1\n",
    "                elif derivation == \"werk\":\n",
    "                    total_werk += 1\n",
    "                    \n",
    "        try: compoundSplit(word)\n",
    "        except:\n",
    "            total_compounds += 1 # upon inspection almost all exceptions are hyphenated words, i.e. compounds\n",
    "            continue\n",
    "        if len(compoundSplit(word)) > 1:\n",
    "            total_compounds += 1\n",
    "                    \n",
    "    try: # catch total_nouns divide by 0 exception\n",
    "        df_document.loc[index,\"MO-nom2nouns\"] = total_nom/total_nouns\n",
    "        df_document.loc[index,\"MO-gen2nouns\"] = total_gen/total_nouns\n",
    "        df_document.loc[index,\"MO-dat2nouns\"] = total_dat/total_nouns\n",
    "        df_document.loc[index,\"MO-acc2nouns\"] = total_acc/total_nouns\n",
    "        #df_document.loc[index,\"MO-derived2nouns\"] = total_derived/total_nouns\n",
    "        df_document.loc[index,\"MO-compounds2nouns\"] = total_compounds/total_nouns\n",
    "    except:\n",
    "        df_document.loc[index,\"MO-nom2nouns\"] = 0\n",
    "        df_document.loc[index,\"MO-gen2nouns\"] = 0\n",
    "        df_document.loc[index,\"MO-dat2nouns\"] = 0\n",
    "        df_document.loc[index,\"MO-acc2nouns\"] = 0\n",
    "        #df_document.loc[index,\"MO-derived2nouns\"] = 0\n",
    "        df_document.loc[index,\"MO-compounds2nouns\"] = 0\n",
    "        \n",
    "    try: # catch total_verbs divide by 0 exception\n",
    "        df_document.loc[index,\"MO-inf2verbs\"] = total_infinitives/total_verbs\n",
    "        df_document.loc[index,\"MO-part2verbs\"] = total_participles/total_verbs\n",
    "        df_document.loc[index,\"MO-imp2verbs\"] = total_imperatives/total_verbs\n",
    "        df_document.loc[index,\"MO-1st2finverbs\"] = total_first/total_finite\n",
    "        df_document.loc[index,\"MO-2nd2finverbs\"] = total_second/total_finite\n",
    "        df_document.loc[index,\"MO-3rd2finverbs\"] = total_third/total_finite\n",
    "        df_document.loc[index,\"MO-subj2finverbs\"] = total_subj/total_finite\n",
    "        df_document.loc[index,\"MO-finverbs2verbs\"] = total_finite/total_verbs\n",
    "        df_document.loc[index,\"MO-modverbs2verbs\"] = total_modal/total_verbs\n",
    "        df_document.loc[index,\"MO-auxverbs2verbs\"] = total_auxiliary/total_verbs\n",
    "    except:\n",
    "        df_document.loc[index,\"MO-inf2verbs\"] = 0\n",
    "        df_document.loc[index,\"MO-part2verbs\"] = 0\n",
    "        df_document.loc[index,\"MO-imp2verbs\"] = 0\n",
    "        df_document.loc[index,\"MO-1st2finverbs\"] = 0\n",
    "        df_document.loc[index,\"MO-2nd2finverbs\"] = 0\n",
    "        df_document.loc[index,\"MO-3rd2finverbs\"] = 0\n",
    "        df_document.loc[index,\"MO-subj2finverbs\"] = 0\n",
    "        df_document.loc[index,\"MO-finverbs2verbs\"] = 0\n",
    "        df_document.loc[index,\"MO-modverbs2verbs\"] = 0\n",
    "        df_document.loc[index,\"MO-auxverbs2verbs\"] = 0\n",
    "              \n",
    "    df_document.loc[index,\"MO-verbspersent\"] = total_verbs/num_sentences\n",
    "    df_document.loc[index,\"MO-keit2nouns\"] = total_keit/len(word_list)\n",
    "    df_document.loc[index,\"MO-ung2nouns\"] = total_ung/len(word_list)\n",
    "    df_document.loc[index,\"MO-werk2nouns\"] = total_werk/len(word_list)\n",
    "    \n",
    "def fill_document_vector(df,df_document):\n",
    "    add_morph_columns(df_document)\n",
    "    index = 0\n",
    "    for all_sentences in df.loc[:,'RFTagger']:\n",
    "        if all_sentences is not None:\n",
    "            all_sentences = all_sentences[:-5] # remove the empty last sentence [] as following line won't work\n",
    "            all_sentences += \"]\" # nasty preprocessing necessary to keep list structure for literal_eval\n",
    "            all_sentences = ast.literal_eval(all_sentences)\n",
    "            text_length = 0\n",
    "            word_list = []\n",
    "            morph_dict = defaultdict(int)\n",
    "            for sentence in all_sentences:\n",
    "                text_length += len(sentence)\n",
    "                for word_features in sentence:\n",
    "                    word_list.append(word_features[0])\n",
    "                    word_features = word_features[1:] #exclude the word itself and lemma at end (leads to too many features)\n",
    "                    for token in word_features:\n",
    "                        df_document.loc[index,\"MO-\"+token] +=1\n",
    "                        if token == \"Nom\" or token== \"Gen\" or token==\"Dat\" or token==\"Acc\":\n",
    "                            if \"N\" in word_features: # only add nouns with above cases\n",
    "                                morph_dict[token] += 1\n",
    "                                continue\n",
    "                            else: continue\n",
    "                        morph_dict[token] += 1\n",
    "            df_document.loc[index] = df_document.loc[index] / text_length # normalize each value with the total text length       \n",
    "            fill_morph_features(df_document, word_list, morph_dict, index)\n",
    "            index +=1\n",
    "            \n",
    "def save_df(path,df):\n",
    "    df.to_csv(path,sep=\"|\",index=False)\n",
    "\n",
    "# get total number of sentences and all features contained in dataset in order to create vector columns\n",
    "all_features = get_all_features(df)  \n",
    "\n",
    "# document level vector, i.e. each row in the feature vector represents one document\n",
    "zero_data = np.zeros(shape=(len(df),len(all_features))) # create 1 row in the feature vector per document\n",
    "df_document = pd.DataFrame(zero_data,columns=sorted(all_features))\n",
    "y = get_classifications(df)\n",
    "\n",
    "fill_document_vector(df,df_document)\n",
    "display(df_document.head())\n",
    "print(list(df_document))\n",
    "\n",
    "df = pd.concat([df,df_document], axis=1)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "filename = \"06_MorphologicalFeatures_df.csv\"\n",
    "save_df(filename,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
